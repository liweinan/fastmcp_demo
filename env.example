# FastMCP Demo 环境变量配置

# MCP服务器URL（Docker内部使用服务名，本地使用localhost）
MCP_SERVER_URL=http://localhost:8100

# LLM模型配置
# 仅支持Llama 3.1 8B-Instruct（支持原生tool_calls）
# 模型文件路径（相对于项目根目录）
LLAMA_MODEL_PATH=./models/llama-3.1-8b-instruct-q4_k_m.gguf

# 代理配置（可选，用于 Docker 构建时）
# build.sh 会自动读取这些环境变量并传递给 Docker 构建
#
# 优先级：BUILD_PROXY > PROXY_URL > HTTP_PROXY > http_proxy
#
# 推荐方式：直接设置 BUILD_PROXY（最高优先级，将直接传递给 Dockerfile）
# BUILD_PROXY=http://your-proxy:port
# BUILD_PROXY=http://localhost:7890
#
# 其他可选方式（build.sh 会自动推导）：
# PROXY_URL=http://your-proxy:port
# HTTP_PROXY=http://your-proxy:port
# HTTPS_PROXY=http://your-proxy:port
# http_proxy=http://your-proxy:port
# https_proxy=http://your-proxy:port
# NO_PROXY=localhost,127.0.0.1
#
# 重要说明：
# 1. 如果代理地址使用 localhost，Dockerfile 会自动将其转换为 host.docker.internal
#    例如：BUILD_PROXY=http://localhost:7890 
#         在容器内将使用：http://host.docker.internal:7890
#
# 2. 代理将应用于以下构建步骤：
#    - apt-get 包管理器（Debian 仓库下载）
#    - uv 下载和安装（https://astral.sh/uv/install.sh）
#    - Python 下载和安装（通过 uv）
#    - pip/uv sync 依赖安装
#
# 3. Docker daemon 拉取基础镜像时不使用此代理
#    如果基础镜像拉取失败，请在 Docker Desktop 中配置代理设置